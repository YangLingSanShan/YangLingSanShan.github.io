<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>lpr的摸鱼记录v1.0 | YangLingSanShan</title><meta name="author" content="舲."><meta name="copyright" content="舲."><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="lpr的搜推入门（七）">
<meta property="og:type" content="article">
<meta property="og:title" content="lpr的摸鱼记录v1.0">
<meta property="og:url" content="https://yanglingsanshan.github.io/2025/07/16/fishing1/index.html">
<meta property="og:site_name" content="YangLingSanShan">
<meta property="og:description" content="lpr的搜推入门（七）">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yanglingsanshan.github.io/img/avatar.png">
<meta property="article:published_time" content="2025-07-16T11:55:00.000Z">
<meta property="article:modified_time" content="2025-07-16T12:15:00.918Z">
<meta property="article:author" content="舲.">
<meta property="article:tag" content="推荐系统">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yanglingsanshan.github.io/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "lpr的摸鱼记录v1.0",
  "url": "https://yanglingsanshan.github.io/2025/07/16/fishing1/",
  "image": "https://yanglingsanshan.github.io/img/avatar.png",
  "datePublished": "2025-07-16T11:55:00.000Z",
  "dateModified": "2025-07-16T12:15:00.918Z",
  "author": [
    {
      "@type": "Person",
      "name": "舲.",
      "url": "https://yanglingsanshan.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/luoxiaohan_3.jpg"><link rel="canonical" href="https://yanglingsanshan.github.io/2025/07/16/fishing1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'lpr的摸鱼记录v1.0',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg" style="background-image: url(/img/luoxiaohan_1.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">YangLingSanShan</span></a><a class="nav-page-title" href="/"><span class="site-name">lpr的摸鱼记录v1.0</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">lpr的摸鱼记录v1.0</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-16T11:55:00.000Z" title="发表于 2025-07-16 19:55:00">2025-07-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-16T12:15:00.918Z" title="更新于 2025-07-16 20:15:00">2025-07-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h1 id="月度总结1-0">月度总结1.0</h1>
<h2 id="摸鱼快乐">摸鱼快乐！</h2>
<p>近一个月参与了<strong>Wearfit Pro</strong> App （简称WP）中推荐系统排序链路的CTR预估模块研发与优化工作。本文将总结个人在模型设计、特征工程与线上效果验证过程中的一些思考与收获。</p>
<p>Wearfit Pro 的视频内容模块以类似小红书的“双列短视频”形式展现，为用户提供更轻量化的健康生活内容推荐体验。尽管 App 本身还具备运动手环连接、健康数据指导、商城等功能模块，但这些与推荐系统链路关联较弱，当前我们主要聚焦在视频推荐部分的 CTR 预估优化上。线下关注的指标包括AUC、用户AUC（uAUC）、加权用户AUC（wuAUC）、MAE、MSE等，线上指标包括点赞收藏率、CTR（点击率）、用户渗透率以及后一天的用户留存率。</p>
<p>由于视频推荐功能刚刚上线，各类机制仍处于初步构建阶段，数据端也呈现出一系列挑战性特征，包括：</p>
<ol>
<li><strong>用户行为稀疏</strong>：整体用户点击率偏低，绝大多数用户每天仅触发极少推荐行为，训练样本稀疏；除此之外，通过数据分析还能检测到大量爬虫行为的存在。</li>
<li><strong>冷启动问题突出</strong>：无论是新用户还是新内容（如短视频），都存在较长的“空窗期”，难以快速融入排序模型；</li>
<li><strong>数据波动大</strong>：推荐位存在样式变动、内容池更新频繁，且由于审核机制刚刚健全，推流了大量科技数码视频以冲洗违规内容，导致样本分布不稳定；</li>
<li><strong>负样本数量庞大</strong>：多数曝光未转化为点击，样本极度不平衡，训练易偏向负类。</li>
</ol>
<p>基于以上问题，在特征工程、模型架构设计、Embedding表达优化、损失函数&amp;负采样策略等角度进行了多轮线上/线下实验。</p>
<hr>
<h2 id="特征工程">特征工程</h2>
<p>由于视频推荐模块刚刚上线，行为数据尚不完备，我们在构建 CTR 预估模型时，特征工程成为提升模型效果的关键环节。我们从以下几个维度出发，设计并优化了多类特征：</p>
<h3 id="基础侧特征">基础侧特征</h3>
<p>主要包括数值特征、离散特征以及列表类特征（基本处理逻辑还是常用的归一化、补空、分桶、log映射、截断等等），下面仅仅介绍一下我们能获取的特征不做详细数据展示，对统计和交叉特征仅作大概描述。</p>
<ul>
<li><strong>用户侧特征</strong>：包括如用户ID、设备型号、系统版本、性别、位置等常见特征，以及用户偏好等</li>
<li><strong>物品侧特征</strong>：如视频ID、视频时长、作者、内容类型、发布时间等；</li>
<li><strong>上下文特征</strong>：如曝光时间段、曝光次数、曝光场景等；</li>
</ul>
<h3 id="统计特征：">统计特征：</h3>
<p>为了刻画用户的偏好强度，我们构建了若干基于滑窗的行为统计特征，例如用户窗口内活跃度、用户偏好和类别匹配结果的语义化、内容曝光情况、基于地理位置/IP分块的统计数据。这些特征一定程度上缓解了线下训练冷启动时用户画像难以描述的问题，以及线上实验用户渗透、留存过低的问题。（虽然大部分尝试没有收益）</p>
<h3 id="交叉特征：">交叉特征：</h3>
<p>为了增强模型的表达能力，我们引入部分组合特征。显示交叉特征的构建往往收益较大，但需要注意，不同模型对相同显式交叉特征利用效果不同（通过<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.03895">TayFCS: Training-free Align Your Frames with Concepts and Semantics</a>验证成功）。目前的结论是场景是一个很有趣的特征。</p>
<h2 id="模型架构设计">模型架构设计</h2>
<p>目前已经探索的模型/方法：</p>
<ol>
<li>ESMM：这篇在之前的blog中提及过，是用于解决Selective Bias的架构，其本质是两个MoE模型分别作ctr和cvr的结果，该模型效果不好并且训练时间大大增加。查阅文章后，认为问题出在shared bottom，如果任务相关性不强，它优化的时候会出现梯度冲突、任务优化优先级有先后（跷跷板现象）</li>
<li>MMoE：同上，多专家之间出现严重的极化现象，有的专家根本无法发挥作用，训练时间过长。</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.20900">GNOLR</a>：这篇仅仅实现了GNOLR的Neural版本，这一基础版本用户偏好子任务相互独立，无法捕捉到每种反馈所特有的特征依赖关系，导致训练出来的累计概率不单调递增。为解决这种独立问题，提出的Nested版本使用用户偏好序列长度个双塔结构，最后逐用户偏好程度嵌套，训练成本过高，不适合用于当前场景。</li>
<li>Wide&amp;Deep、DCN、DCNv2等传统网络：效果与MLP接近（初步怀疑是交叉特征不足限制模型发挥，但是构造交叉特征会消耗大量推理耗时），于是后面的工作基本上在MLP上完成</li>
<li>DCN^2：提出了一种新的仅密集层（onlydense layer），作为交叉层的替代方案。仅密集层在原始的密集空间中执行显式的特征交叉操作，而不是先将输入投影到低维空间。在资源不受限的情况下更优，但当前场景必须用cpu进行训练及推理。</li>
</ol>
<p>除此之外，还尝试了其他包括知识蒸馏的优化方法，均会导致超时or某一线上指标崩盘。</p>
<hr>
<h2 id="embedding表达优化">Embedding表达优化</h2>
<p>在本项目中，Embedding 表达能力对 CTR 模型性能有着直接影响。由于推荐链路中的用户ID、物品ID、tag类别 等字段均为稀疏离散特征，其分布高度不均，Embedding 学习面临以下主要挑战：</p>
<ol>
<li>长尾现象严重：呈现典型的 Zipf 分布，少数高频 ID 占据大部分曝光，绝大多数 ID 为低频甚至一次都未出现的冷门值。</li>
<li>活跃用户训练不足：区别于其他常见App，WP场景下活跃用户极少，导致缺乏有效Embedding。</li>
<li>Embedding过拟合与稳定性问题：在短期上线数据中，由于样本量有限，Embedding层易出现过拟合波动。</li>
</ol>
<p>进行了如下的探索：</p>
<ol>
<li>基于Group Embedding的冷启动优化。选择若干个分组字段，对用户进行分组（在我们的数据中，性别是一个比较良好的分组字段）。之后在预测阶段，如果遇到了冷启动用户，则使用该用户所在组别的平均user_id的嵌入值来表示当前用户的嵌入值，而非随机嵌入或生成全0向量，可以一定程度上缓解用户冷启动带来的模型表现下降。</li>
<li>复现了Sparse Optimizer和Frequency-Adaptive Learning Rate(FAL)，这两个组件的作用分别是加速embedding层收敛和根据ID频率动态调整学习率缓解多轮过拟合。在本地和榜单测试中，引入这两个策略会显著加快模型收敛，并提升模型表现。但是引入Sparse Optimizer会导致模型出现更严重的过拟合(One-Epoch)现象，判断是原文的使用场景与我们的并不相同，因此原文需要调高嵌入层的学习率以缓解欠拟合现象，但由于我们的场景下，嵌入层本身就有一定的过拟合，因此实际上并不能照搬论文的内容。</li>
<li>使用Sbert对tag进行语义化处理，即使用Sbert替代nn.Embedding处理单独的tag</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2403.00798.pdf">Helen</a>优化器：发现特征频率与特征emb的最高特征值之间存在正相关性，这种相关性凸显了参数空间中损失的不平衡分布，使得传统的优化器很难发现有效泛化的平坦的最小值，而导致将模型优化到次优状态，因而选择利用频率Hessian特征值正则化优化CTR模型。效果一般</li>
<li>NEFTune：这篇文章本来是LLM方向，主要思想是加入噪声的嵌入提升指令微调效果，用在推荐系统这边存在一点缓解过拟合提高AUC的效果。</li>
<li>对过高频tag进行降采样后，再决定是否保留。（这一出发点是之前运维推流大量视频去除违规视频产生的）</li>
</ol>
<hr>
<h2 id="损失函数-负采样">损失函数&amp;负采样</h2>
<p>虽然这一内容是召回层应该做的，但是我们排序阶段获得的数据仍出现正负样本急剧不平衡的问题。具体情况是当前场景正负样本比例近1:500，导致click发生的类别在训练时反向传播梯度更新的几率更小，对loss的贡献也比较低，不利于其收敛，最终导致click不发生的类别主导了模型，使得模型整体偏向它们。针对此类问题，主要探索了Focal Loss一系列方法和负样本降采样。</p>
<h3 id="loss方法">Loss方法</h3>
<p>针对正负样本急剧不平衡的问题，在CV目标识别领域有专门的解决方法：OHEM方法——Focal Loss及其变体。这个<a target="_blank" rel="noopener" href="https://github.com/shuxinyin/NLP-Loss-Pytorch">链接</a>给出了经典的Focal loss，GHM loss的实现。他们的数学本质都是<strong>重加权</strong>，通过修改模型的 loss，在 loss 计算上，加大对少样本的 loss 奖励。</p>
<p>Focal Loss 是一种解决不平衡问题的经典 loss，基本思想就是把注意力集中于那些预测不准的样本上。GHM (gradient harmonizing mechanism) 是一种梯度调和机制（怎么又是gradient norm），GHM Loss 的改进思想有两点：</p>
<ol>
<li>在使模型继续保持对 hard example 关注的基础上，使模型不去关注这些离群样本；</li>
<li>另外 Focal Loss 中， 的值分别由实验经验得出，而一般情况下超参 是互相影响的，应当共同进行实验得到。</li>
</ol>
<p>这两种方法均在线下进行测试，效果不如传统的pointwise的BSE loss和<strong>pairwise的Ranking loss</strong>。感觉问题出在hard样本在推荐领域纯为特征表示难以分辨，而非cv的类似离群点导致的难样本，本质上来讲还是特征稀疏导致的。</p>
<h3 id="负样本降采样">负样本降采样</h3>
<p>这个有点像data pruning（什么逆天联动），本质上都是抛弃一部分样本，但dp的时候往往导致性能的下降，而在极度不平衡的时候，负采样会提高一些性能。在实践中，更多的是做的uv向的负采样，对无点击行为的用户进行采样（这样的用户巨多）。尝试的策略如下：</p>
<ol>
<li>全抛弃：这个虽然夸张，但是在线上获得了较好的用户渗透、点赞收藏等收益。从业务角度分析来说，就是这一行为导致线上为用户推流的都是常客看的视频，属于在讨好老用户（不管新用户死活）。当然，这一策略也导致了线上留存的暴跌。</li>
<li>随机采样、均匀采样方法</li>
<li>设计曝光置信度进行筛选：曝光置信度与Exposure BIas相关，其本质思想是“曝光而未点击的样本不一定是用户不喜欢的，直接作为负样本其置信度存疑”。因此，基于<a target="_blank" rel="noopener" href="https://www.zhihu.com/tardis/bd/ans/3353825224?source_id=1001">这篇文章</a>的想法，进行对曝光置信度的模拟。</li>
<li>基于<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2409.07237">综述文章</a>，尝试多种静态采样方法：包括基于用户相似度的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2507.06503">USD</a>方法、基于模拟社交网络图的<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.07734">SamWalker++</a>方法。</li>
</ol>
<p>这些还在探索中，目前看到线下效果随机的采样效果确实不如各种启发式/非启发式算法。</p>
<hr>
<h2 id="反思">反思</h2>
<p>也算是入门了搜推领域，做了一些实际的尝试并取得了一定的效果，写完技术性的总结，也应该写一些业务上的总结：</p>
<ol>
<li>数据的重要性：模型训练的基础是特征，特征的基础是数据，在实际场景中，数据不能简单看作一组数字or字符串，它们具有实际的意义。因此，在进行特征工程的时候，不仅需要考虑数据分布等基本模型训练能用到的信息，还需要考虑其是否能为实际指标作出什么贡献。</li>
<li>线上指标和线下指标的gap：做的不管是ctr预估还是对用户完播的预估，其本质上还是对线上实际业务指标的映射，哪怕线下效果再好，也很难说线上能在诸多指标上取得进步。</li>
<li>Traceback的重要性：当一个策略不太好使的时候，需要反思其是否具有业务意义，需要追溯其数据输出等自顶而下地查问题。</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://yanglingsanshan.github.io">舲.</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://yanglingsanshan.github.io/2025/07/16/fishing1/">https://yanglingsanshan.github.io/2025/07/16/fishing1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://yanglingsanshan.github.io" target="_blank">YangLingSanShan</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/05/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88KuaiFormer%EF%BC%89/" title="推荐系统学习（KuaiFormer）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">推荐系统学习（KuaiFormer）</div></div><div class="info-2"><div class="info-item-1">KuaiFormer （好久没学习了…）  论文：KuaiFormer: Transformer-Based Retrieval at Kuaishou  这是一篇LLM4Rec的论文，旨在探索大语言模型在推荐系统领域的应用。这篇文章声称从根本上定义检索功能，将传统的得分估计（如CTR预估），转换为Transformer驱动的下一步预测范式，从而实时提取兴趣点，提高检索性能。但也仅仅是使用了LLM的架构，直接以Llama Transformer架构作为Backbone,...</div></div></div></a><a class="pagination-related" href="/2025/07/17/MMoE/" title="lpr的摸鱼记录v2.0"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">lpr的摸鱼记录v2.0</div></div><div class="info-2"><div class="info-item-1">MMoE的一些浅薄经验及思考 近年来，多任务学习（Multi-task Learning, MTL）在推荐系统、广告点击率预测（CTR/CVR）等场景中得到了广泛应用。其中，**MMoE（Multi-gate...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/17/MMoE/" title="lpr的摸鱼记录v2.0"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">lpr的摸鱼记录v2.0</div></div><div class="info-2"><div class="info-item-1">MMoE的一些浅薄经验及思考 近年来，多任务学习（Multi-task Learning, MTL）在推荐系统、广告点击率预测（CTR/CVR）等场景中得到了广泛应用。其中，**MMoE（Multi-gate...</div></div></div></a><a class="pagination-related" href="/2025/04/09/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88CTR%E9%A2%84%E4%BC%B0%EF%BC%89/" title="推荐系统学习（CTR预估）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-09</div><div class="info-item-2">推荐系统学习（CTR预估）</div></div><div class="info-2"><div class="info-item-1">KuaiFormer （好久没学习了…）  论文：KuaiFormer: Transformer-Based Retrieval at Kuaishou  这是一篇LLM4Rec的论文，旨在探索大语言模型在推荐系统领域的应用。这篇文章声称从根本上定义检索功能，将传统的得分估计（如CTR预估），转换为Transformer驱动的下一步预测范式，从而实时提取兴趣点，提高检索性能。但也仅仅是使用了LLM的架构，直接以Llama Transformer架构作为Backbone,...</div></div></div></a><a class="pagination-related" href="/2025/05/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88KuaiFormer%EF%BC%89/" title="推荐系统学习（KuaiFormer）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-23</div><div class="info-item-2">推荐系统学习（KuaiFormer）</div></div><div class="info-2"><div class="info-item-1">KuaiFormer （好久没学习了…）  论文：KuaiFormer: Transformer-Based Retrieval at Kuaishou  这是一篇LLM4Rec的论文，旨在探索大语言模型在推荐系统领域的应用。这篇文章声称从根本上定义检索功能，将传统的得分估计（如CTR预估），转换为Transformer驱动的下一步预测范式，从而实时提取兴趣点，提高检索性能。但也仅仅是使用了LLM的架构，直接以Llama Transformer架构作为Backbone,...</div></div></div></a><a class="pagination-related" href="/2025/04/15/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88Word2vec%EF%BC%89/" title="推荐系统学习（Word2vec）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-15</div><div class="info-item-2">推荐系统学习（Word2vec）</div></div><div class="info-2"><div class="info-item-1">推荐系统学习（Word2vec） CBoW &amp; Skip-gram模型架构 2003年，Bengio等人发表了一篇开创性的文章：A neural probabilistic language model[3]。在这篇文章里，他们总结出了一套用神经网络建立统计语言模型的框架（Neural Network Language Model，以下简称NNLM），并首次提出了word embedding的概念，从而奠定了包括word2vec在内后续研究word representation learning的基础。 NNLM模型的基本思想可以概括如下：  假定词表中的每一个word都对应着一个连续的特征向量； 假定一个连续平滑的概率模型，输入一段词向量的序列，可以输出这段序列的联合概率； 同时学习词向量的权重和概率模型里的参数。   我们可以将整个模型拆分成两部分加以理解：   首先是一个线性的Embedding层。它将输入的N−1个one-hot词向量，通过一个共享的D×V的矩阵C，映射为N−1个分布式的词向量（distributed...</div></div></div></a><a class="pagination-related" href="/2025/04/18/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%86%B7%E5%90%AF%E5%8A%A8%EF%BC%89/" title="推荐系统学习（冷启动）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-18</div><div class="info-item-2">推荐系统学习（冷启动）</div></div><div class="info-2"><div class="info-item-1">冷启动 冷启动介绍 冷启动： 对于新注册的用户或者新入库的标的物, 该怎么给新用户推荐标的物让用户满意，怎么将新标的物分发出去，推荐给喜欢它的用户。 如果是新开发的产品，初期用户很少，用户行为也不多，常用的协同过滤、深度学习等依赖大量用户行为的算法不能很好的训练出精准的推荐模型, 怎么让推荐系统很好的运转起来，让推荐变得越来越准确，这个问题就是系统冷启动。 分类：   标的物冷启动：也称为“物品冷启动”或“内容冷启动”，指的是系统中新增了某个推荐对象（如商品、电影、文章等），但由于该物品还没有用户互动数据（点击、评分、购买等），导致系统无法判断哪些用户可能喜欢它。   用户冷启动：指的是系统中新增用户或活跃度极低的用户，由于其没有或几乎没有行为数据，系统难以判断该用户的兴趣偏好，难以进行个性化推荐。   **系统冷启动： 整个推荐系统刚刚上线或处于早期阶段，缺乏足够的用户数据和物品数据，导致推荐算法无法有效学习   冷启动挑战：  我们一般对新用户知之甚少，...</div></div></div></a><a class="pagination-related" href="/2025/04/11/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88%E9%80%89%E6%8B%A9%E6%80%A7%E5%81%8F%E5%B7%AE%EF%BC%89/" title="推荐系统学习（选择性偏差）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-11</div><div class="info-item-2">推荐系统学习（选择性偏差）</div></div><div class="info-2"><div class="info-item-1">推荐系统中的Selection bias 推荐系统中的bias Selection bias：当用户能够自由地选择给哪些物品打分的时候，则评分数据不是随机丢失的（missing not at random, MNAR），观测到的交互数据的分布将不能代表整体数据的分布。（当用户拥有自由选择权的时候，更倾向于给自己喜欢的物品打分。） Conformity bias：用户的打分会倾向于和群体一致，即使群体的打分有时候和用户的判断是有区别的，用户的这种倾向将使得评分并不能准确反映用户的偏好。大部分人都有从众的倾向，当用户发现自己的判断与大众不一致时，很可能改变自己的评分，而让自己的评分向大众的评分靠拢。 Exposure bias：用户只会暴露在一部分的物品上，因此没有交互过的物品不一定是用户不喜欢的，还可能是用户没看到。用户和物品没有交互存在两种可能性：用户没看到物品、用户不喜欢物品，直接讲没有交互过的物品当作负样本（用户不喜欢）会引入偏差。 Position...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">舲.</div><div class="author-info-description">琼楼玉宇 倒了阵形</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/YangLingSanShan"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">轨迹改变角落交错，寂寞城市又再探戈，天空闪过灿烂花火，和你不再为爱奔波。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%88%E5%BA%A6%E6%80%BB%E7%BB%931-0"><span class="toc-number">1.</span> <span class="toc-text">月度总结1.0</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%B8%E9%B1%BC%E5%BF%AB%E4%B9%90"><span class="toc-number">1.1.</span> <span class="toc-text">摸鱼快乐！</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E4%BE%A7%E7%89%B9%E5%BE%81"><span class="toc-number">1.2.1.</span> <span class="toc-text">基础侧特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E7%89%B9%E5%BE%81%EF%BC%9A"><span class="toc-number">1.2.2.</span> <span class="toc-text">统计特征：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E7%89%B9%E5%BE%81%EF%BC%9A"><span class="toc-number">1.2.3.</span> <span class="toc-text">交叉特征：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.3.</span> <span class="toc-text">模型架构设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#embedding%E8%A1%A8%E8%BE%BE%E4%BC%98%E5%8C%96"><span class="toc-number">1.4.</span> <span class="toc-text">Embedding表达优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E8%B4%9F%E9%87%87%E6%A0%B7"><span class="toc-number">1.5.</span> <span class="toc-text">损失函数&amp;负采样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#loss%E6%96%B9%E6%B3%95"><span class="toc-number">1.5.1.</span> <span class="toc-text">Loss方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E9%99%8D%E9%87%87%E6%A0%B7"><span class="toc-number">1.5.2.</span> <span class="toc-text">负样本降采样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8D%E6%80%9D"><span class="toc-number">1.6.</span> <span class="toc-text">反思</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/MMoE/" title="lpr的摸鱼记录v2.0">lpr的摸鱼记录v2.0</a><time datetime="2025-07-17T13:23:00.000Z" title="发表于 2025-07-17 21:23:00">2025-07-17</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/16/fishing1/" title="lpr的摸鱼记录v1.0">lpr的摸鱼记录v1.0</a><time datetime="2025-07-16T11:55:00.000Z" title="发表于 2025-07-16 19:55:00">2025-07-16</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/23/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88KuaiFormer%EF%BC%89/" title="推荐系统学习（KuaiFormer）">推荐系统学习（KuaiFormer）</a><time datetime="2025-05-23T03:15:00.000Z" title="发表于 2025-05-23 11:15:00">2025-05-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/22/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88%E9%87%8D%E6%8E%92%E5%BA%8F%EF%BC%89/" title="推荐系统学习（重排序）">推荐系统学习（重排序）</a><time datetime="2025-04-22T03:47:00.000Z" title="发表于 2025-04-22 11:47:00">2025-04-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/18/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%86%B7%E5%90%AF%E5%8A%A8%EF%BC%89/" title="推荐系统学习（冷启动）">推荐系统学习（冷启动）</a><time datetime="2025-04-18T08:58:00.000Z" title="发表于 2025-04-18 16:58:00">2025-04-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By 舲.</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>